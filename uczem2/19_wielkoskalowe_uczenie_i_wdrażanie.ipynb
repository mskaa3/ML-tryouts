{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "19_wielkoskalowe_uczenie_i_wdrażanie.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZCn4Cp8d_kp",
        "colab_type": "text"
      },
      "source": [
        "**Rozdział 19. Wielkoskalowe uczenie i wdrażanie modeli TensorFlow**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj-3RU1wd_kr",
        "colab_type": "text"
      },
      "source": [
        "_Notatnik ten zawiera przykładowy kod i rozwiązania ćwiczeń opisane w rozdziale 19._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3KcTxuNd_ks",
        "colab_type": "text"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/19_training_and_deploying_at_scale.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Uruchom w Google Colab (wersja angielska)</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyGr3UwMd_kt",
        "colab_type": "text"
      },
      "source": [
        "# Konfiguracja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRnLzEhVd_ku",
        "colab_type": "text"
      },
      "source": [
        "Importujmy najpierw kilka popularnych modułów, upewnijmy się, że będą wstawiane wykresy MatplotLib, a także przygotujmy funkcję zapisującą rysunki. Sprawdzimy także, czy jest zainstalowane środowisko Python 3.5 lub nowsze (możliwe, że kod będzie działał w środowisku Python 2.x, zostało ono jednak porzucone, dlatego zalecamy korzystanie ze środowiska Python 3), a także biblioteka Scikit-Learn 0.20 lub nowsza i TensorFlow 2.0 lub nowszy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQpqZW7cd_kv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "640105e5-5120-4f9c-b08a-55b4897057c7"
      },
      "source": [
        "# Wymagane środowisko Python ≥3.5\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Wymagana biblioteka Scikit-Learn ≥0.20\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version istnieje jedynie w środowisku Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "    !curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "    !apt update && apt-get install -y tensorflow-model-server\n",
        "    !pip install -q -U tensorflow-serving-api\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# Wymagany moduł TensorFlow ≥2.0\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.test.is_gpu_available():\n",
        "    print(\"Nie wykryto procesora graficznego. Bez niego sieci splotowe mogą działać bardzo powoli.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Kliknij Runtime > Change runtime i wybierz akcelerator graficzny.\")\n",
        "\n",
        "# Importuje standardowe biblioteki\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Aby wyniki uzyskiwane w tym notatniku były odtwarzalne\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Do rysowania ładnych wykresów\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Ścieżka zapisywania rysunków\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"R19\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"rysunki\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Zapisywanie rysunku\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0  28028      0 --:--:-- --:--:-- --:--:-- 28298\n",
            "OK\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Get:10 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [361 B]\n",
            "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [354 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [836 kB]\n",
            "Get:16 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [83.6 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [11.7 kB]\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [824 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [44.7 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,128 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [31.0 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [7,641 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,351 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [4,247 B]\n",
            "Get:26 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [36.9 kB]\n",
            "Get:28 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,775 kB]\n",
            "Get:29 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [857 kB]\n",
            "Fetched 7,287 kB in 57s (127 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "107 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 107 not upgraded.\n",
            "Need to get 175 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.1.0 [175 MB]\n",
            "Fetched 175 MB in 2s (71.1 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 145113 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.1.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.1.0) ...\n",
            "Setting up tensorflow-model-server (2.1.0) ...\n",
            "WARNING:tensorflow:From <ipython-input-1-7810e1a8ebff>:24: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaFbrD4bd_ky",
        "colab_type": "text"
      },
      "source": [
        "# Wdrażanie modeli TensorFlow do usługi TensorFlow Serving (TFS)\n",
        "Skorzystamy z interfejsu REST lub gRPC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtGqgvsid_kz",
        "colab_type": "text"
      },
      "source": [
        "## Zapisywanie/wczytywanie obiektu `SavedModel`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LcAvq0Hd_k0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "813faace-60ee-4ea9-94a5-e6d2ddfe3c81"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_test = X_test[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_new = X_test[:3]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObsdZzm-d_k2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e32cc8e8-3ed3-4fbf-f0cf-a081a12457e6"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 6s 113us/sample - loss: 0.7031 - accuracy: 0.8237 - val_loss: 0.3718 - val_accuracy: 0.9032\n",
            "Epoch 2/10\n",
            "55000/55000 [==============================] - 4s 76us/sample - loss: 0.3532 - accuracy: 0.9012 - val_loss: 0.3000 - val_accuracy: 0.9150\n",
            "Epoch 3/10\n",
            "55000/55000 [==============================] - 4s 76us/sample - loss: 0.3031 - accuracy: 0.9145 - val_loss: 0.2667 - val_accuracy: 0.9270\n",
            "Epoch 4/10\n",
            "55000/55000 [==============================] - 4s 75us/sample - loss: 0.2732 - accuracy: 0.9236 - val_loss: 0.2442 - val_accuracy: 0.9308\n",
            "Epoch 5/10\n",
            "55000/55000 [==============================] - 4s 75us/sample - loss: 0.2504 - accuracy: 0.9297 - val_loss: 0.2256 - val_accuracy: 0.9388\n",
            "Epoch 6/10\n",
            "55000/55000 [==============================] - 4s 76us/sample - loss: 0.2315 - accuracy: 0.9350 - val_loss: 0.2106 - val_accuracy: 0.9416\n",
            "Epoch 7/10\n",
            "55000/55000 [==============================] - 4s 76us/sample - loss: 0.2153 - accuracy: 0.9397 - val_loss: 0.1988 - val_accuracy: 0.9458\n",
            "Epoch 8/10\n",
            "55000/55000 [==============================] - 4s 75us/sample - loss: 0.2017 - accuracy: 0.9441 - val_loss: 0.1867 - val_accuracy: 0.9486\n",
            "Epoch 9/10\n",
            "55000/55000 [==============================] - 4s 75us/sample - loss: 0.1896 - accuracy: 0.9465 - val_loss: 0.1785 - val_accuracy: 0.9516\n",
            "Epoch 10/10\n",
            "55000/55000 [==============================] - 4s 79us/sample - loss: 0.1789 - accuracy: 0.9501 - val_loss: 0.1690 - val_accuracy: 0.9538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6f632856a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMw1P3iBd_k6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5a0cb2a1-98ca-4f8d-f189-40eb02a845d1"
      },
      "source": [
        "np.round(model.predict(X_new), 2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7KTTJ34d_k9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d341ecc-1c12-4e6f-ce7c-176661545e22"
      },
      "source": [
        "model_version = \"0001\"\n",
        "model_name = \"moj_model_mnist\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "model_path"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'moj_model_mnist/0001'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubDymVuCd_k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf {model_name}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "985FcBA7d_lC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1c2af3b0-ceea-40a0-bb55-f93fe84cfb46"
      },
      "source": [
        "tf.saved_model.save(model, model_path)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: moj_model_mnist/0001/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Cb6h6Qd_lE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6d58a0dd-698f-48aa-b642-662e4306a702"
      },
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "moj_model_mnist/\n",
            "    0001/\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.index\n",
            "            variables.data-00000-of-00002\n",
            "            variables.data-00001-of-00002\n",
            "        assets/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSDxdDZWd_lH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8bf98b8c-26d3-4b9c-ac84-46e0f887dfcc"
      },
      "source": [
        "!saved_model_cli show --dir {model_path}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel contains the following tag-sets:\n",
            "serve\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9sPUdiNd_lJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3fa40380-4f9e-4e6c-88d5-ae4125ad566b"
      },
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"__saved_model_init_op\"\n",
            "SignatureDef key: \"serving_default\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFvyS4Chd_lQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4dc6479f-4e44-406d-ec5a-14d6ddae959b"
      },
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve \\\n",
        "                      --signature_def serving_default"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['flatten_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 28, 28, 1)\n",
            "      name: serving_default_flatten_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense_1'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXKhP3Xqd_lS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b17a2d4-58f7-4f8a-dede-eca4064363f0"
      },
      "source": [
        "!saved_model_cli show --dir {model_path} --all"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['flatten_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_flatten_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVbog3-Md_lU",
        "colab_type": "text"
      },
      "source": [
        "Wprowadźmy nowe przykłady do pliku `npy`, dzięki czemu będziemy mogli z łatwością przekazywać je do modelu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcF0Oxvd_lV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"moje_testy_mnist.npy\", X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtYppcyHd_lX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceeba586-61d3-44ba-844a-8bf669881573"
      },
      "source": [
        "input_name = model.input_names[0]\n",
        "input_name"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'flatten_input'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx9RcIpTd_lZ",
        "colab_type": "text"
      },
      "source": [
        "Skorzystajmy teraz z narzędzia `saved_model_cli`, aby uzyskać prognozy dla dopiero co zapisanych przykładów:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcRH0HBEd_la",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "143499cc-4b9e-4362-a361-3b304d46c5cc"
      },
      "source": [
        "!saved_model_cli run --dir {model_path} --tag_set serve \\\n",
        "                     --signature_def serving_default    \\\n",
        "                     --inputs {input_name}=my_mnist_tests.npy"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-2.1.0/python3.6/bin/saved_model_cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/tensorflow-2.1.0/python3.6/tensorflow_core/python/tools/saved_model_cli.py\", line 990, in main\n",
            "    args.func(args)\n",
            "  File \"/tensorflow-2.1.0/python3.6/tensorflow_core/python/tools/saved_model_cli.py\", line 720, in run\n",
            "    args.inputs, args.input_exprs, args.input_examples)\n",
            "  File \"/tensorflow-2.1.0/python3.6/tensorflow_core/python/tools/saved_model_cli.py\", line 635, in load_inputs_from_input_arg_string\n",
            "    data = np.load(file_io.FileIO(filename, mode='rb'), allow_pickle=True)\n",
            "  File \"/tensorflow-2.1.0/python3.6/numpy/lib/npyio.py\", line 436, in load\n",
            "    magic = fid.read(N)\n",
            "  File \"/tensorflow-2.1.0/python3.6/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\n",
            "    self._preread_check()\n",
            "  File \"/tensorflow-2.1.0/python3.6/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\n",
            "    compat.as_bytes(self.__name), 1024 * 512)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: my_mnist_tests.npy; No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgyjPI-Bd_lc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "06e53347-73b4-43dd-a019-c5901dc44c79"
      },
      "source": [
        "np.round([[1.1739199e-04, 1.1239604e-07, 6.0210604e-04, 2.0804715e-03, 2.5779348e-06,\n",
        "           6.4079795e-05, 2.7411186e-08, 9.9669880e-01, 3.9654213e-05, 3.9471846e-04],\n",
        "          [1.2294615e-03, 2.9207937e-05, 9.8599273e-01, 9.6755642e-03, 8.8930705e-08,\n",
        "           2.9156188e-04, 1.5831805e-03, 1.1311053e-09, 1.1980456e-03, 1.1113169e-07],\n",
        "          [6.4066830e-05, 9.6359509e-01, 9.0598064e-03, 2.9872139e-03, 5.9552520e-04,\n",
        "           3.7478798e-03, 2.5074568e-03, 1.1462728e-02, 5.5553433e-03, 4.2495009e-04]], 2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs3l6E-gd_le",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow Serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv3q3QHhd_le",
        "colab_type": "text"
      },
      "source": [
        "Zainstaluj [Dockera](https://docs.docker.com/install/), jeśli jeszcze tego nie zrobiłeś. Następnie uruchom polecenie:\n",
        "\n",
        "```bash\n",
        "docker pull tensorflow/serving\n",
        "\n",
        "export ML_PATH=$HOME/um # lub dowolna inna lokalizacja projektu\n",
        "docker run -it --rm -p 8500:8500 -p 8501:8501 \\\n",
        "   -v \"$ML_PATH/moj_model_mnist:/models/moj_model_mnist\" \\\n",
        "   -e MODEL_NAME=moj_model_mnist \\\n",
        "   tensorflow/serving\n",
        "```\n",
        "Gdy już przestaniesz korzystać z serwera, wyłączysz go za pomocą kombinacji klawiszy Ctrl+C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpQIoQ_qd_lf",
        "colab_type": "text"
      },
      "source": [
        "Ewentualnie, jeżeli jest zainstalowany `tensorflow_model_server` (tzn. jeśli uruchomiłeś ten notatnik w środowisku Colab), to poniższe trzy komórki uruchomią serwer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl7iHf9wd_lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = os.path.split(os.path.abspath(model_path))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQKUPowtd_li",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bde1564-9f4a-4d7f-dd9a-a96b20b0de4c"
      },
      "source": [
        "%%bash --bg\n",
        "nohup tensorflow_model_server \\\n",
        "     --rest_api_port=8501 \\\n",
        "     --model_name=my_mnist_model \\\n",
        "     --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r8T7PVvd_lk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85b970d1-0b86-4f6b-9e36-535888b9e464"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_y2qfiDd_lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "input_data_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist(),\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5F8DMaOd_lo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "43c7abf7-c9e5-4ab3-950e-17919b5f99a6"
      },
      "source": [
        "repr(input_data_json)[:1500] + \"...\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\'{\"signature_name\": \"serving_default\", \"instances\": [[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.32941177487373...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzq_mHoCd_lq",
        "colab_type": "text"
      },
      "source": [
        "Wykorzystajmy teraz interfejs REST do uzyskiwania prognoz:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTO9qmx0d_lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
        "response = requests.post(SERVER_URL, data=input_data_json)\n",
        "response.raise_for_status() # raise an exception in case of error\n",
        "response = response.json()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN7An5nId_lt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbab2601-b2a3-4f53-bfb3-81a4ca29193c"
      },
      "source": [
        "response.keys()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4cq0oMxd_lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f979fa82-5330-449d-93b8-8d047e7ce0d8"
      },
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fnMspFXd_lx",
        "colab_type": "text"
      },
      "source": [
        "### Korzystanie z interfejsu gRPC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE9UTn_8d_ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
        "\n",
        "request = PredictRequest()\n",
        "request.model_spec.name = model_name\n",
        "request.model_spec.signature_name = \"serving_default\"\n",
        "input_name = model.input_names[0]\n",
        "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjokgbK7d_l1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import grpc\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "channel = grpc.insecure_channel('localhost:8500')\n",
        "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "response = predict_service.Predict(request, timeout=10.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf8CNA7Nd_l3",
        "colab_type": "code",
        "colab": {},
        "outputId": "aef66665-5507-4775-80c6-72451473a9bf"
      },
      "source": [
        "response"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "outputs {\n",
              "  key: \"dense_4\"\n",
              "  value {\n",
              "    dtype: DT_FLOAT\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 3\n",
              "      }\n",
              "      dim {\n",
              "        size: 10\n",
              "      }\n",
              "    }\n",
              "    float_val: 2.0824443708988838e-05\n",
              "    float_val: 1.4913139168015732e-08\n",
              "    float_val: 0.0004813199338968843\n",
              "    float_val: 0.001888890634290874\n",
              "    float_val: 2.682592992186983e-07\n",
              "    float_val: 8.666840585647151e-06\n",
              "    float_val: 1.6853943241024183e-10\n",
              "    float_val: 0.9975269436836243\n",
              "    float_val: 3.833709342870861e-05\n",
              "    float_val: 3.4738284739432856e-05\n",
              "    float_val: 0.00017358684272039682\n",
              "    float_val: 0.0002858016814570874\n",
              "    float_val: 0.9816810488700867\n",
              "    float_val: 0.0157401692122221\n",
              "    float_val: 1.1949770339914068e-10\n",
              "    float_val: 0.00023017563216853887\n",
              "    float_val: 3.078056761296466e-05\n",
              "    float_val: 5.393230750883049e-09\n",
              "    float_val: 0.0018584482604637742\n",
              "    float_val: 1.8884094288296183e-09\n",
              "    float_val: 3.397366526769474e-05\n",
              "    float_val: 0.9835277795791626\n",
              "    float_val: 0.001533020636998117\n",
              "    float_val: 0.0014515116345137358\n",
              "    float_val: 0.00018795969663187861\n",
              "    float_val: 0.0011680654715746641\n",
              "    float_val: 0.0014667459763586521\n",
              "    float_val: 0.006120447069406509\n",
              "    float_val: 0.004315734840929508\n",
              "    float_val: 0.00019466254161670804\n",
              "  }\n",
              "}\n",
              "model_spec {\n",
              "  name: \"my_mnist_model\"\n",
              "  version {\n",
              "    value: 2\n",
              "  }\n",
              "  signature_name: \"serving_default\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghRdVRnxd_l5",
        "colab_type": "text"
      },
      "source": [
        "Przekształcamy odpowiedź w tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cIywOoGDd_l6",
        "colab_type": "code",
        "colab": {},
        "outputId": "7af8aebd-0a96-4b9a-cb41-89c1301b269d"
      },
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "y_proba = tf.make_ndarray(outputs_proto)\n",
        "y_proba.round(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.98, 0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_TU8mn9d_l8",
        "colab_type": "text"
      },
      "source": [
        "Lub w tablicę NumPy, jeżeli Twój klient nie zawiera biblioteki TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ncTWZSOd_l9",
        "colab_type": "code",
        "colab": {},
        "outputId": "bb43443b-780a-4b0e-e7b2-519612a6d84f"
      },
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "shape = [dim.size for dim in outputs_proto.tensor_shape.dim]\n",
        "y_proba = np.array(outputs_proto.float_val).reshape(shape)\n",
        "y_proba.round(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.98, 0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pXEs1R3d_l_",
        "colab_type": "text"
      },
      "source": [
        "## Wdrażanie nowej wersji modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-M3GvCVnd_l_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "386c4d60-b651-4716-c1a4-2c7792312edc"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 5s 82us/sample - loss: 0.7049 - accuracy: 0.8066 - val_loss: 0.3452 - val_accuracy: 0.9032\n",
            "Epoch 2/10\n",
            "55000/55000 [==============================] - 4s 78us/sample - loss: 0.3213 - accuracy: 0.9074 - val_loss: 0.2655 - val_accuracy: 0.9244\n",
            "Epoch 3/10\n",
            "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2664 - accuracy: 0.9230 - val_loss: 0.2281 - val_accuracy: 0.9350\n",
            "Epoch 4/10\n",
            "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2347 - accuracy: 0.9321 - val_loss: 0.2046 - val_accuracy: 0.9432\n",
            "Epoch 5/10\n",
            "55000/55000 [==============================] - 4s 78us/sample - loss: 0.2121 - accuracy: 0.9382 - val_loss: 0.1878 - val_accuracy: 0.9492\n",
            "Epoch 6/10\n",
            "55000/55000 [==============================] - 4s 78us/sample - loss: 0.1935 - accuracy: 0.9442 - val_loss: 0.1746 - val_accuracy: 0.9510\n",
            "Epoch 7/10\n",
            "55000/55000 [==============================] - 4s 78us/sample - loss: 0.1787 - accuracy: 0.9486 - val_loss: 0.1655 - val_accuracy: 0.9538\n",
            "Epoch 8/10\n",
            "55000/55000 [==============================] - 4s 78us/sample - loss: 0.1662 - accuracy: 0.9527 - val_loss: 0.1570 - val_accuracy: 0.9560\n",
            "Epoch 9/10\n",
            "55000/55000 [==============================] - 4s 79us/sample - loss: 0.1553 - accuracy: 0.9554 - val_loss: 0.1471 - val_accuracy: 0.9576\n",
            "Epoch 10/10\n",
            "55000/55000 [==============================] - 4s 78us/sample - loss: 0.1456 - accuracy: 0.9579 - val_loss: 0.1410 - val_accuracy: 0.9602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXNcK2sSd_mB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e986e59-84fc-4eec-b8d3-dc6d144e77be"
      },
      "source": [
        "model_version = \"0002\"\n",
        "model_name = \"moj_model_mnist\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "model_path"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'moj_model_mnist/0002'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVL0-8ZFd_mD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e1b9022-0cf4-4b27-c6e5-fc76d9a389e8"
      },
      "source": [
        "tf.saved_model.save(model, model_path)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: moj_model_mnist/0002/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aN5264gd_mG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "96e0bc9e-0437-4923-ef7a-87d640144b63"
      },
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "moj_model_mnist/\n",
            "    0001/\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.index\n",
            "            variables.data-00000-of-00002\n",
            "            variables.data-00001-of-00002\n",
            "        assets/\n",
            "    0002/\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.index\n",
            "            variables.data-00000-of-00002\n",
            "            variables.data-00001-of-00002\n",
            "        assets/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_ea6g2id_mH",
        "colab_type": "text"
      },
      "source": [
        "**Ostrzeżenie**: Może upłynąć trochę czasu, zanim nowy model zostanie wczytany przez TensorFlow Serving."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pXa6Ng9d_mI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
        "            \n",
        "response = requests.post(SERVER_URL, data=input_data_json)\n",
        "response.raise_for_status()\n",
        "response = response.json()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4E-DMoyd_mJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da7fac83-b2a1-4444-a39b-5c0ce8828b90"
      },
      "source": [
        "response.keys()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg3ShZB7d_mM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "90520404-ed70-4b72-cdea-ee1679c2eb2b"
      },
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4at5Vn5Ld_mP",
        "colab_type": "text"
      },
      "source": [
        "# Wdrażanie modelu do serwisu GCP Google"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2vCULGYd_mQ",
        "colab_type": "text"
      },
      "source": [
        "W książce znajdziesz instrukcje wdrażania modelu do środowiska Google Cloud AI Platform, pobierania klucza prywatnego konta usługi i zapisania go w pliku `moj_klucz_konta_uslugi.json`. Trzeba także zaktualizować `project_id`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a_lubQ_d_mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_id = \"onyx-smoke-242003\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5XkiypSd_mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import googleapiclient.discovery\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"moj_klucz_konta_uslugi.json\"\n",
        "model_id = \"moj_model_mnist\"\n",
        "model_path = \"projects/{}/models/{}\".format(project_id, model_id)\n",
        "model_path += \"/versions/v0001/\" # jeżeli chcesz uruchomić określoną wersję\n",
        "ml_resource = googleapiclient.discovery.build(\"ml\", \"v1\").projects()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgZBd8NAd_mT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X):\n",
        "    input_data_json = {\"signature_name\": \"serving_default\",\n",
        "                       \"instances\": X.tolist()}\n",
        "    request = ml_resource.predict(name=model_path, body=input_data_json)\n",
        "    response = request.execute()\n",
        "    if \"error\" in response:\n",
        "        raise RuntimeError(response[\"error\"])\n",
        "    return np.array([pred[output_name] for pred in response[\"predictions\"]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XotQAgCTd_mX",
        "colab_type": "code",
        "colab": {},
        "outputId": "9702e396-bfa5-4ed2-c9e9-559b8f6f34aa"
      },
      "source": [
        "Y_probas = predict(X_new)\n",
        "np.round(Y_probas, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT9IjunFd_mY",
        "colab_type": "text"
      },
      "source": [
        "# Korzystanie z kart graficznych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6-27Klld_mZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "bf8634c4-0494-49dd-a685-4520be6c7082"
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK8tHwznd_mb",
        "colab_type": "code",
        "colab": {},
        "outputId": "5545c951-5106-4fe5-93a7-a36c18bf86cf"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1YE8TtCd_md",
        "colab_type": "code",
        "colab": {},
        "outputId": "74d253fa-840b-477f-c2d2-97b909cf7f95"
      },
      "source": [
        "tf.test.is_built_with_cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l62sjQBWd_mi",
        "colab_type": "code",
        "colab": {},
        "outputId": "92613622-5f56-4757-925a-447e7702fde8"
      },
      "source": [
        "from tensorflow.python.client.device_lib import list_local_devices\n",
        "\n",
        "devices = list_local_devices()\n",
        "devices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 11178133101787456811]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So_4WwQkd_mj",
        "colab_type": "text"
      },
      "source": [
        "# Uczenie rozproszone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsO8Td9cd_mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNkAx-vkd_mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    return keras.models.Sequential([\n",
        "        keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                            padding=\"same\", input_shape=[28, 28, 1]),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"), \n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(units=64, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(units=10, activation='softmax'),\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xecW_5wdd_mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "model = create_model()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gOTDMNbd_mp",
        "colab_type": "code",
        "colab": {},
        "outputId": "c939bf7d-95f3-4e7a-d9e7-b977f87591ed"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "distribution = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Zmienia domyślny algorytm All-Reduce:\n",
        "#distribution = tf.distribute.MirroredStrategy(\n",
        "#    cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
        "\n",
        "# Wyznacza listę używanych procesorów graficznych:\n",
        "#distribution = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
        "\n",
        "# Wprowadza strategię magazynu centralnego:\n",
        "#distribution = tf.distribute.experimental.CentralStorageStrategy()\n",
        "\n",
        "#resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "#tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#distribution = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "with distribution.scope():\n",
        "    model = create_model()\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=keras.optimizers.SGD(lr=1e-2),\n",
        "                  metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0603 15:31:26.178871 140735810999168 cross_device_ops.py:1178] There is non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_ldA3Nzd_mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100 # must be divisible by the number of workers\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGdVNuqnd_ms",
        "colab_type": "code",
        "colab": {},
        "outputId": "8466316a-8a52-4c13-bb25-9d596c74d631"
      },
      "source": [
        "model.predict(X_new)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09101252, 0.07083996, 0.06410537, 0.11957529, 0.06693752,\n",
              "        0.05124901, 0.04676544, 0.23180223, 0.13522181, 0.12249089],\n",
              "       [0.08099081, 0.12387844, 0.14915964, 0.13171668, 0.05875394,\n",
              "        0.08834281, 0.16267018, 0.06899565, 0.07834874, 0.05714307],\n",
              "       [0.04303756, 0.2682051 , 0.0909673 , 0.11496522, 0.06084979,\n",
              "        0.07125981, 0.08520001, 0.08517107, 0.09236596, 0.0879782 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvfBKp9Zd_mt",
        "colab_type": "text"
      },
      "source": [
        "Niestandardowa pętla uczenia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTrOiccFd_mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "K = keras.backend\n",
        "\n",
        "distribution = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with distribution.scope():\n",
        "    model = create_model()\n",
        "    optimizer = keras.optimizers.SGD()\n",
        "\n",
        "with distribution.scope():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).repeat().batch(batch_size)\n",
        "    input_iterator = distribution.make_dataset_iterator(dataset)\n",
        "    \n",
        "@tf.function\n",
        "def train_step():\n",
        "    def step_fn(inputs):\n",
        "        X, y = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            Y_proba = model(X)\n",
        "            loss = K.sum(keras.losses.sparse_categorical_crossentropy(y, Y_proba)) / batch_size\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    per_replica_losses = distribution.experimental_run(step_fn, input_iterator)\n",
        "    mean_loss = distribution.reduce(tf.distribute.ReduceOp.SUM,\n",
        "                                    per_replica_losses, axis=None)\n",
        "    return mean_loss\n",
        "\n",
        "n_epochs = 10\n",
        "with distribution.scope():\n",
        "    input_iterator.initialize()\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoka numer {}/{}\".format(epoch + 1, n_epochs))\n",
        "        for iteration in range(len(X_train) // batch_size):\n",
        "            print(\"\\rFunkcja straty: {:.3f}\".format(train_step().numpy()), end=\"\")\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VecxXu3nd_mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100 # musi być podzielne przez liczbę roboczych grup zadań\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLCU-Khtd_mw",
        "colab_type": "text"
      },
      "source": [
        "## Uczenie za pomocą wielu serwerów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G64SQewud_mw",
        "colab_type": "text"
      },
      "source": [
        "Klaster TensorFlow to grupa równolegle przetwarzanych (zazwyczaj na osobnych komputerach) procesów TensorFlow, komunikujących się ze sobą w celu ukończenia jakiegoś zadania, na przykład wytrenowania lub uruchomienia sieci neuronowej. Każdy proces w klastrze TF nosi nazwę zadania lub serwera TF. Każde zadanie zawiera własny adres IP, port i przynależy do określonego typu (zwanego także rolą albo grupą zadań). Wyróżniamy cztery typy zadań: roboczą grupę zadań (`\"worker\"`), serwer główny (`\"chief\"`), serwer parametrów (`\"ps\"`) i ewaluatora (`\"evaluator\"`):\n",
        "* Każda **robocza grupa zadań** przeprowadza obliczenia, zazwyczaj na komputerze wyposażonym w co najmniej jedną kartę graficzną. \n",
        "* **Serwer główny** również przeprowadza obliczenia (jak robocza grupa zadań), ale zajmuje się także dodatkowymi czynnościami, takimi jak generowanie komunikatów zdarzeń TensorFlow czy zapisywanie punktów kontrolnych. W każdym klastrze znajduje się jeden serwer główny. Jeżeli nie został wyznaczony żaden serwer główny, rola ta przypada pierwszej roboczej grupie zadań.\n",
        "* **Serwer parametrów** zajmuje się jedynie wartościami zmiennych i mieści się zazwyczaj na komputerze wyposażonym wyłącznie w jednostkę CPU.\n",
        "* **Ewaluator** zajmuje się oceną modelu. Zazwyczaj w klastrze występuje jeden ewaluator.\n",
        "\n",
        "Zbiór zadań tego samego typu często jest nazywany grupą zadań. Na przykład, grupa zadań \"worker\" stanowi zbiór wszystkich roboczych grup zadań.\n",
        "\n",
        "Przed uruchomieniem klastra TensorFlow należy go najpierw zdefiniować. Oznacza to określenie adresu IP, portu i typu każdego zadania. Na przykład, poniższa specyfikacja klastra wyznacza klaster trzyzadaniowy (dwie robocze grupy zadań i jeden serwer parametrów). Specyfikacja klastra to słownik zawierający po jednym kluczu na każdą grupę zadań, natomiast jego wartości tworzą listy adresów zadań:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"worker\": [\"moja-robocza-grupa-zadan0.przyklad.com:9876\", \"moja-robocza-grupa-zadan1.przyklad.com:9876\"],\n",
        "    \"ps\": [\"moj-ps0.przyklad.com:9876\"]\n",
        "}\n",
        "```\n",
        "\n",
        "Domyślnie zadania w klastrze mogą się ze sobą komunikować, dlatego skonfiguruj odpowiednio zaporę sieciową tak, aby umożliwiała komunikację pomiędzy tymi komputerami poprzez wyznaczone porty (zazwyczaj ułatwiasz sobie życie, jeśli na wszystkich komputerach będziesz korzystać z tego samego portu).\n",
        "\n",
        "W momencie uruchamiania zadania musisz podać mu specyfikację klastra, a także wyznaczyć mu typ i indeks (np. indeks zadania jest również nazywany identyfikatorem zadania). Najprostszym sposobem zdefiniowania wszystkich elementów jednocześnie (specyfikacji klastra, a także typu i indeksu bieżącego zadania) jest wyznaczenie zmiennej środowiskowej `TF_CONFIG` przed uruchomieniem programu. Musi mieć ona postać słownika kodowanego w formacie JSON, przechowującego specyfikację klastra (klucz `\"cluster\"`), a także typ i indeks bieżącego zadania (klucz `\"task\"`). Na przykład, poniższa zmienna środowiskowa `TF_CONFIG` wykorzystuje zdefiniowany przez nas wcześniej klaster i za jej pomocą wyznaczamy pierwszą roboczą grupę zadań jako zadanie do uruchomienia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmmd7Gted_mx",
        "colab_type": "code",
        "colab": {},
        "outputId": "e41b26cb-582c-40a5-fd5e-327c6bc08ced"
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
        "    \"cluster\": {\n",
        "        \"worker\": [\"moja-praca0.przyklad.com:9876\", \"moja-praca1.przyklad.com:9876\"],\n",
        "        \"ps\": [\"moj-ps0.przyklad.com:9876\"]\n",
        "    },\n",
        "    \"task\": {\"type\": \"worker\", \"index\": 0}\n",
        "})\n",
        "print(\"TF_CONFIG='{}'\".format(os.environ[\"TF_CONFIG\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF_CONFIG='{\"cluster\": {\"worker\": [\"my-work0.example.com:9876\", \"my-work1.example.com:9876\"], \"ps\": [\"my-ps0.example.com:9876\"]}, \"task\": {\"type\": \"worker\", \"index\": 0}}'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1V--Nknd_mz",
        "colab_type": "text"
      },
      "source": [
        "Niektóre plarformy (np. Google Cloud ML Engine) automatycznie wyznaczają tę zmienną środowiskową."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xiZ_JXtd_m0",
        "colab_type": "text"
      },
      "source": [
        "Możesz następnie stworzyć prosty skrypt Python uruchamiający zadanie. Można używać tego samego skryptu na wszystkich komputerach, ponieważ będzie wczytywał zmienną `TF_CONFIG`, dzięki której będzie wiadomo, które zadanie ma zostać uruchomione:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOhbafjld_m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
        "worker0 = tf.distribute.Server(resolver.cluster_spec(),\n",
        "                               job_name=resolver.task_type,\n",
        "                               task_index=resolver.task_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMfzQ2fAd_m2",
        "colab_type": "text"
      },
      "source": [
        "Możesz także wyznaczyć specyfikację klastra bezpośrednio w Pythonie zamiast korzystać ze zmiennej środowiskowej:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEI5RjXqd_m2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_spec = tf.train.ClusterSpec({\n",
        "    \"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"],\n",
        "    \"ps\": [\"127.0.0.1:9903\"]\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBqv-R9Bd_m4",
        "colab_type": "text"
      },
      "source": [
        "Możesz następnie uruchomić serwer poprzez przekazanie mu specyfikacji klastra i określenie jego typu oraz indeksu. Zrealizujmy dwa pozostałe zadania (pamiętaj, że zazwyczaj chcemy uruchmiać tylko jedno zadanie na każdym komputerze; teraz uruchamiamy trzy na jednym urządzeniu wyłącznie w celach dydaktycznych):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh-gwqPAd_m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#worker1 = tf.distribute.Server(cluster_spec, job_name=\"worker\", task_index=1)\n",
        "ps0 = tf.distribute.Server(cluster_spec, job_name=\"ps\", task_index=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diQLshHxd_m5",
        "colab_type": "code",
        "colab": {},
        "outputId": "8a480c63-2a16-4941-9e12-8c9a715bcc4b"
      },
      "source": [
        "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
        "    \"cluster\": {\n",
        "        \"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"],\n",
        "        \"ps\": [\"127.0.0.1:9903\"]\n",
        "    },\n",
        "    \"task\": {\"type\": \"worker\", \"index\": 1}\n",
        "})\n",
        "print(repr(os.environ[\"TF_CONFIG\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'{\"cluster\": {\"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"], \"ps\": [\"127.0.0.1:9903\"]}, \"task\": {\"type\": \"worker\", \"index\": 1}}'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAud91f5d_m6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distribution = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
        "    \"cluster\": {\n",
        "        \"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"],\n",
        "        \"ps\": [\"127.0.0.1:9903\"]\n",
        "    },\n",
        "    \"task\": {\"type\": \"worker\", \"index\": 1}\n",
        "})\n",
        "#CUDA_VISIBLE_DEVICES=0 \n",
        "\n",
        "with distribution.scope():\n",
        "    model = create_model()\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=keras.optimizers.SGD(lr=1e-2),\n",
        "                  metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihnTDLHId_m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Na początku programu (zrestartuj jądro przed uruchomieniem tej komórki)\n",
        "distribution = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
        "\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full[..., np.newaxis] / 255.\n",
        "X_test = X_test[..., np.newaxis] / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_new = X_test[:3]\n",
        "\n",
        "n_workers = 2\n",
        "batch_size = 32 * n_workers\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train[..., np.newaxis], y_train)).repeat().batch(batch_size)\n",
        "    \n",
        "def create_model():\n",
        "    return keras.models.Sequential([\n",
        "        keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                            padding=\"same\", input_shape=[28, 28, 1]),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"), \n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(units=64, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(units=10, activation='softmax'),\n",
        "    ])\n",
        "\n",
        "with distribution.scope():\n",
        "    model = create_model()\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=keras.optimizers.SGD(lr=1e-2),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(dataset, steps_per_epoch=len(X_train)//batch_size, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuea9iFfd_m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Strojenie hiperparametrów\n",
        "\n",
        "# Komunikuje się wyłącznie z serwerem ps\n",
        "config_proto = tf.ConfigProto(device_filters=['/job:ps', '/job:worker/task:%d' % tf_config['task']['index']])\n",
        "config = tf.estimator.RunConfig(session_config=config_proto)\n",
        "# domyślne od wersji 1.10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sn20r73d_nA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strategy.num_replicas_in_sync"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}